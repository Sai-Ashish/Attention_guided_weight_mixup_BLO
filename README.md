# Attention guided weight mixup using bi-level optimization

Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts - NAACL'24
â€‹
This folder contains the implementation of our proposed method using BERT-LARGE model.
â€‹
### Create and activate conda env
```console
conda env create -f environment.yml
```
### Start the experiments
```console
python multi_lanuch_script.py
```
(or)
```console
bash run.sh
```
### ğŸ“ Code File Descriptions

- ğŸ“„ **bert_modeling.py**: Contains BERT modeling enhancements with alpha parameters used for the resultant weight node estimation.

- ğŸ“„ **blo.py**: Implements the mixup of weights using alpha parameters.

- ğŸ“„ **run_glue_mlo.py**: This is the primary script to execute.

- ğŸ“„ **multi_launch_script.py**: Utilizes multiprocessing to execute multiple experiments concurrently.
